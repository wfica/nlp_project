{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMvhf3SxhgRW"
      },
      "outputs": [],
      "source": [
        "!apt install musescore"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install musicautobot"
      ],
      "metadata": {
        "id": "8Dhr3KFkhni4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastai==1.0.61"
      ],
      "metadata": {
        "id": "ufdHmVDZirOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show fastai"
      ],
      "metadata": {
        "id": "jscSIyMafKGV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b5da4bf-e479-4869-da96-4c03af358c74"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: fastai\n",
            "Version: 1.0.61\n",
            "Summary: fastai makes deep learning with PyTorch faster, more accurate, and easier\n",
            "Home-page: https://github.com/fastai/fastai\n",
            "Author: Jeremy Howard\n",
            "Author-email: info@fast.ai\n",
            "License: Apache Software License 2.0\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: matplotlib, numexpr, fastprogress, nvidia-ml-py3, torchvision, spacy, Pillow, numpy, beautifulsoup4, packaging, bottleneck, torch, pyyaml, pandas, scipy, requests\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import random\n",
        "import numpy as np\n",
        "import music21\n",
        "import musicautobot\n",
        "from musicautobot.music_transformer import transform\n",
        "from musicautobot.vocab import MusicVocab\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.functional import softmax\n",
        "from matplotlib import pyplot as plt \n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using {DEVICE}.\")\n",
        "SEQUENCE_LENGTH = 15"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlYzOruahpA_",
        "outputId": "32415add-4df1-4940-ce13-1d111f5b548c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE0S4TGzhr_W",
        "outputId": "bbf8470f-fb4f-4912-8d99-85a0fd810822"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = Path(\"drive/MyDrive/projectNLP/data\")\n",
        "PT_PATH = DATA_PATH / \"processed\"\n",
        "vocab = MusicVocab.create()"
      ],
      "metadata": {
        "id": "eyGwyO8rhuZ8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_filepaths():\n",
        "    for subdir in (PT_PATH).iterdir():\n",
        "      for track_filepath in subdir.iterdir():\n",
        "        yield track_filepath"
      ],
      "metadata": {
        "id": "TZagMXmAjHxk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = list(get_filepaths())"
      ],
      "metadata": {
        "id": "lNFGlf-rqZ-H"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_TRAIN_RATIO = 0.2\n",
        "total_num_files = len(files)\n",
        "tst_num_files = int(TEST_TRAIN_RATIO * total_num_files)\n",
        "trn_num_files = total_num_files - tst_num_files\n",
        "print( f\"train test num_files: {trn_num_files}, {tst_num_files}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Llweuej6rAeo",
        "outputId": "03c73d06-43fb-4236-9e84-631c0f792395"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train test num_files: 1088, 271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_files, test_files = torch.utils.data.random_split(files, [trn_num_files, tst_num_files], generator=torch.Generator().manual_seed(42))\n",
        "train_files = list(train_files)[:20]"
      ],
      "metadata": {
        "id": "j-Jr81IerRAj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKf3mw8Uh90V",
        "outputId": "112e54ba-ad5d-4751-9bb2-9e0524abbce8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('drive/MyDrive/projectNLP/data/processed/Henry Butler/Down by the Riverside.pt'),\n",
              " PosixPath('drive/MyDrive/projectNLP/data/processed/Frankie Goes to Hollywood/Relax.2.pt'),\n",
              " PosixPath('drive/MyDrive/projectNLP/data/processed/Led Zeppelin/When the Levee Breaks.1.pt'),\n",
              " PosixPath('drive/MyDrive/projectNLP/data/processed/Hall & Oates/Did It In A Minute.pt'),\n",
              " PosixPath('drive/MyDrive/projectNLP/data/processed/Dire Straits/Sultans of Swing.11.pt'),\n",
              " PosixPath('drive/MyDrive/projectNLP/data/processed/Jimi Hendrix/All Along The Watchtower.1.pt'),\n",
              " PosixPath('drive/MyDrive/projectNLP/data/processed/Mariah Carey/Make It Happen.1.pt'),\n",
              " PosixPath('drive/MyDrive/projectNLP/data/processed/Mariah Carey/Someday.1.pt'),\n",
              " PosixPath('drive/MyDrive/projectNLP/data/processed/Billy Idol/(Do Not) Stand in the Shadows.pt'),\n",
              " PosixPath('drive/MyDrive/projectNLP/data/processed/Gino Paoli/Il cielo in una stanza.pt'),\n",
              " PosixPath('drive/MyDrive/projectNLP/data/processed/Jackson Michael/Rock With You.3.pt'),\n",
              " PosixPath('drive/MyDrive/projectNLP/data/processed/George Baker Selection/Santa Lucia by Night.pt'),\n",
              " PosixPath('drive/MyDrive/projectNLP/data/processed/Dorsey/Besame Mucho.2.pt'),\n",
              " PosixPath('drive/MyDrive/projectNLP/data/processed/Frank Sinatra/These Foolish Things.pt'),\n",
              " PosixPath('drive/MyDrive/projectNLP/data/processed/Gilbert & Sullivan/The Sun, Whose Rays.pt'),\n",
              " PosixPath(\"drive/MyDrive/projectNLP/data/processed/Mariah Carey/I'll Be There.2.pt\"),\n",
              " PosixPath('drive/MyDrive/projectNLP/data/processed/Dee/True Love.pt'),\n",
              " PosixPath('drive/MyDrive/projectNLP/data/processed/Chicago/If You Leave Me Now.5.pt'),\n",
              " PosixPath('drive/MyDrive/projectNLP/data/processed/Led Zeppelin/Ten Years Gone.1.pt'),\n",
              " PosixPath('drive/MyDrive/projectNLP/data/processed/Led Zeppelin/Hats Off to (Roy) Harper.pt')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NotesFile(torch.utils.data.Dataset):\n",
        "    def __init__(self, file, sequence_length=SEQUENCE_LENGTH, device=DEVICE):\n",
        "        self.path = file\n",
        "        self.notes = torch.load(file).to_tensor()\n",
        "        self.sequence_length = sequence_length\n",
        "        self.device = device\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.notes) - self.sequence_length-1\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return (\n",
        "            self.notes[index:index+self.sequence_length],\n",
        "            self.notes[index+1:index+self.sequence_length+1]\n",
        "        )\n",
        "\n",
        "class NotesDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, files, sequence_length=SEQUENCE_LENGTH, device=DEVICE):\n",
        "        self.files = [NotesFile(fn, sequence_length, device) for fn in files]\n",
        "        self.cum_sum = [len(notes) for notes in self.files]\n",
        "        for i in range(1, len(self.files)):\n",
        "          self.cum_sum[i] += self.cum_sum[i-1]\n",
        "        self.sequence_length = sequence_length\n",
        "        self.device = device\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.cum_sum[-1]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        assert index >= 0 and index < len(self)\n",
        "        file = 0\n",
        "        while len(self.files[file]) < index:\n",
        "          index -= len(self.files[file])\n",
        "          file += 1\n",
        "        return self.files[file][index]\n",
        "        \n",
        "train_dataset = NotesDataset(train_files)       "
      ],
      "metadata": {
        "id": "fh7zaZ1Plgmf"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_dataset))\n",
        "print(train_dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mtaNfHcj_VC",
        "outputId": "ec79b89b-28d3-4274-f9be-a9222ff24fbd"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "234966\n",
            "(tensor([  0,   1,   8, 165,  88, 139,  76, 139,   8, 141,  86, 153,  74, 154,\n",
            "          8], device='cuda:0'), tensor([  1,   8, 165,  88, 139,  76, 139,   8, 141,  86, 153,  74, 154,   8,\n",
            "        141], device='cuda:0'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, device=DEVICE, lstm_size=512, embedding_dim=256, num_layers=2, dropout=0.2):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm_size = lstm_size # hidden_size  \n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "        self.device = device\n",
        "        \n",
        "\n",
        "        self.max_bar_len = 1024\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=self.max_bar_len,\n",
        "            embedding_dim=self.embedding_dim,\n",
        "        )\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.embedding_dim,\n",
        "            hidden_size=self.lstm_size,\n",
        "            num_layers=self.num_layers,\n",
        "            dropout=self.dropout,\n",
        "            batch_first=True,\n",
        "        )\n",
        "        self.fc = nn.Linear(self.lstm_size, self.max_bar_len)\n",
        "\n",
        "    def forward(self, x, prev_state):\n",
        "        embed = self.embedding(x)\n",
        "        # print(f\"embed.shape=\\t{embed.shape}\")\n",
        "        output, state = self.lstm(embed, prev_state)\n",
        "        # print(f\"output.shape=\\t{output.shape}\")\n",
        "        logits = self.fc(output)\n",
        "        return logits, state\n",
        "\n",
        "    def init_state(self, batch_size):\n",
        "        if batch_size == 1:\n",
        "          return (torch.zeros(self.num_layers, self.lstm_size).to(self.device),\n",
        "                torch.zeros(self.num_layers, self.lstm_size).to(self.device))\n",
        "        return (torch.zeros(self.num_layers, batch_size, self.lstm_size).to(self.device),\n",
        "                torch.zeros(self.num_layers, batch_size, self.lstm_size).to(self.device))"
      ],
      "metadata": {
        "id": "pFn7NoH2iviJ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMModel() \n",
        "model.to(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxxddOcpnEvk",
        "outputId": "f741ee68-fdad-4a5d-e994-3a5447611fd8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMModel(\n",
              "  (embedding): Embedding(1024, 256)\n",
              "  (lstm): LSTM(256, 512, num_layers=2, batch_first=True, dropout=0.2)\n",
              "  (fc): Linear(in_features=512, out_features=1024, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataset, model, max_epochs = 50, batch_size=512, log_every=100, verbose=True, model_fn = DATA_PATH / 'model_v1.model'):\n",
        "    model.train()\n",
        "\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, drop_last=True, pin_memory=False)\n",
        "    \n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    opt_loss = 1000.0\n",
        "    try:\n",
        "        for epoch in range(max_epochs):\n",
        "            state_h, state_c = model.init_state(batch_size)\n",
        "            \n",
        "            for batch, (x, y) in enumerate(dataloader):\n",
        "                # print(batch)\n",
        "                optimizer.zero_grad()\n",
        "                y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "\n",
        "                # y_pred.shape = (batch_size, seq_len, num_classes); \n",
        "                # dimentions seq_len and num_classes need to be swapped for CrossEntropyLoss\n",
        "                loss = criterion(y_pred.transpose(1, 2), y)\n",
        "\n",
        "                if opt_loss > loss:\n",
        "                  opt_loss = loss.item()\n",
        "                  torch.save(model.state_dict(), model_fn)\n",
        "                  if verbose:\n",
        "                    print({ 'epoch': epoch, 'batch': batch, 'improved_loss': loss.item() })  \n",
        "\n",
        "                state_h = state_h.detach()\n",
        "                state_c = state_c.detach()            \n",
        "\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                if batch % log_every == 0:\n",
        "                  print({ 'epoch': epoch, 'batch': batch, 'loss': loss.item() })\n",
        "            \n",
        "    except KeyboardInterrupt:\n",
        "        pass\n",
        "\n",
        "    model = LSTMModel() \n",
        "    model.load_state_dict(torch.load(model_fn))\n",
        "    model.to(DEVICE)\n",
        "\n",
        "    print({ 'opt_loss': opt_loss })"
      ],
      "metadata": {
        "id": "FJYFH96anHft"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(train_dataset, model)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aak6EjSunbHb",
        "outputId": "c386d863-fa99-4b03-be8e-e6fe843b8f48"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 0, 'batch': 0, 'improved_loss': 2.5826826095581055}\n",
            "{'epoch': 0, 'batch': 0, 'loss': 2.5826826095581055}\n",
            "{'epoch': 0, 'batch': 2, 'improved_loss': 2.564356565475464}\n",
            "{'epoch': 0, 'batch': 5, 'improved_loss': 2.5514607429504395}\n",
            "{'epoch': 0, 'batch': 7, 'improved_loss': 2.4241926670074463}\n",
            "{'epoch': 0, 'batch': 8, 'improved_loss': 2.300684928894043}\n",
            "{'epoch': 0, 'batch': 9, 'improved_loss': 2.2097630500793457}\n",
            "{'epoch': 0, 'batch': 14, 'improved_loss': 2.1770198345184326}\n",
            "{'epoch': 0, 'batch': 17, 'improved_loss': 1.6770827770233154}\n",
            "{'epoch': 0, 'batch': 18, 'improved_loss': 1.2539886236190796}\n",
            "{'epoch': 0, 'batch': 26, 'improved_loss': 1.2246315479278564}\n",
            "{'epoch': 0, 'batch': 37, 'improved_loss': 1.198785424232483}\n",
            "{'epoch': 0, 'batch': 43, 'improved_loss': 1.0894125699996948}\n",
            "{'epoch': 0, 'batch': 47, 'improved_loss': 1.0286377668380737}\n",
            "{'epoch': 0, 'batch': 49, 'improved_loss': 0.955910861492157}\n",
            "{'epoch': 0, 'batch': 55, 'improved_loss': 0.8336182832717896}\n",
            "{'epoch': 0, 'batch': 56, 'improved_loss': 0.7879852652549744}\n",
            "{'epoch': 0, 'batch': 57, 'improved_loss': 0.7825796604156494}\n",
            "{'epoch': 0, 'batch': 58, 'improved_loss': 0.7621676325798035}\n",
            "{'epoch': 0, 'batch': 59, 'improved_loss': 0.7357183694839478}\n",
            "{'epoch': 0, 'batch': 100, 'loss': 1.4162790775299072}\n",
            "{'epoch': 0, 'batch': 200, 'loss': 1.3218122720718384}\n",
            "{'epoch': 0, 'batch': 300, 'loss': 2.873321771621704}\n",
            "{'epoch': 0, 'batch': 368, 'improved_loss': 0.7053375840187073}\n",
            "{'epoch': 0, 'batch': 369, 'improved_loss': 0.6250122785568237}\n",
            "{'epoch': 0, 'batch': 377, 'improved_loss': 0.5959225296974182}\n",
            "{'epoch': 0, 'batch': 378, 'improved_loss': 0.5848771333694458}\n",
            "{'epoch': 0, 'batch': 380, 'improved_loss': 0.5241826772689819}\n",
            "{'epoch': 0, 'batch': 381, 'improved_loss': 0.5204647779464722}\n",
            "{'epoch': 0, 'batch': 386, 'improved_loss': 0.5006617307662964}\n",
            "{'epoch': 0, 'batch': 391, 'improved_loss': 0.47352999448776245}\n",
            "{'epoch': 0, 'batch': 392, 'improved_loss': 0.4673474133014679}\n",
            "{'epoch': 0, 'batch': 398, 'improved_loss': 0.46591654419898987}\n",
            "{'epoch': 0, 'batch': 400, 'loss': 0.8204168081283569}\n",
            "{'epoch': 0, 'batch': 410, 'improved_loss': 0.42080360651016235}\n",
            "{'epoch': 0, 'batch': 420, 'improved_loss': 0.36847496032714844}\n",
            "{'epoch': 1, 'batch': 0, 'loss': 2.4218947887420654}\n",
            "{'epoch': 1, 'batch': 100, 'loss': 1.3971138000488281}\n",
            "{'epoch': 1, 'batch': 200, 'loss': 1.2312774658203125}\n",
            "{'epoch': 1, 'batch': 300, 'loss': 2.8318893909454346}\n",
            "{'epoch': 1, 'batch': 400, 'loss': 0.7562660574913025}\n",
            "{'epoch': 1, 'batch': 420, 'improved_loss': 0.35427722334861755}\n",
            "{'epoch': 2, 'batch': 0, 'loss': 2.3858046531677246}\n",
            "{'epoch': 2, 'batch': 100, 'loss': 1.3630657196044922}\n",
            "{'epoch': 2, 'batch': 200, 'loss': 1.165256142616272}\n",
            "{'epoch': 2, 'batch': 300, 'loss': 2.806493043899536}\n",
            "{'epoch': 2, 'batch': 400, 'loss': 0.7193730473518372}\n",
            "{'epoch': 2, 'batch': 420, 'improved_loss': 0.34394535422325134}\n",
            "{'epoch': 3, 'batch': 0, 'loss': 2.298008680343628}\n",
            "{'epoch': 3, 'batch': 100, 'loss': 1.326796054840088}\n",
            "{'epoch': 3, 'batch': 200, 'loss': 1.109209418296814}\n",
            "{'epoch': 3, 'batch': 300, 'loss': 2.793532609939575}\n",
            "{'epoch': 3, 'batch': 400, 'loss': 0.6819595694541931}\n",
            "{'epoch': 3, 'batch': 420, 'improved_loss': 0.33098480105400085}\n",
            "{'epoch': 4, 'batch': 0, 'loss': 2.2351608276367188}\n",
            "{'epoch': 4, 'batch': 100, 'loss': 1.2921050786972046}\n",
            "{'epoch': 4, 'batch': 200, 'loss': 1.0680160522460938}\n",
            "{'epoch': 4, 'batch': 300, 'loss': 2.727483034133911}\n",
            "{'epoch': 4, 'batch': 400, 'loss': 0.65655916929245}\n",
            "{'epoch': 4, 'batch': 420, 'improved_loss': 0.323757141828537}\n",
            "{'epoch': 5, 'batch': 0, 'loss': 2.1750376224517822}\n",
            "{'epoch': 5, 'batch': 100, 'loss': 1.246405839920044}\n",
            "{'epoch': 5, 'batch': 200, 'loss': 1.027791142463684}\n",
            "{'epoch': 5, 'batch': 300, 'loss': 2.6672544479370117}\n",
            "{'epoch': 5, 'batch': 400, 'loss': 0.6343063116073608}\n",
            "{'epoch': 5, 'batch': 420, 'improved_loss': 0.3188018798828125}\n",
            "{'epoch': 6, 'batch': 0, 'loss': 2.112740993499756}\n",
            "{'epoch': 6, 'batch': 100, 'loss': 1.225677251815796}\n",
            "{'epoch': 6, 'batch': 200, 'loss': 0.9910342693328857}\n",
            "{'epoch': 6, 'batch': 300, 'loss': 2.600318670272827}\n",
            "{'epoch': 6, 'batch': 400, 'loss': 0.6315014958381653}\n",
            "{'epoch': 6, 'batch': 420, 'improved_loss': 0.3152191936969757}\n",
            "{'epoch': 7, 'batch': 0, 'loss': 2.0353450775146484}\n",
            "{'epoch': 7, 'batch': 100, 'loss': 1.2000569105148315}\n",
            "{'epoch': 7, 'batch': 200, 'loss': 0.9573535919189453}\n",
            "{'epoch': 7, 'batch': 300, 'loss': 2.5390522480010986}\n",
            "{'epoch': 7, 'batch': 400, 'loss': 0.6172125339508057}\n",
            "{'epoch': 7, 'batch': 420, 'improved_loss': 0.30812767148017883}\n",
            "{'epoch': 8, 'batch': 0, 'loss': 1.9681735038757324}\n",
            "{'epoch': 8, 'batch': 100, 'loss': 1.1650960445404053}\n",
            "{'epoch': 8, 'batch': 200, 'loss': 0.9277750849723816}\n",
            "{'epoch': 8, 'batch': 300, 'loss': 2.490243673324585}\n",
            "{'epoch': 8, 'batch': 400, 'loss': 0.607969343662262}\n",
            "{'epoch': 9, 'batch': 0, 'loss': 1.8937923908233643}\n",
            "{'epoch': 9, 'batch': 100, 'loss': 1.1493827104568481}\n",
            "{'epoch': 9, 'batch': 200, 'loss': 0.9067081809043884}\n",
            "{'epoch': 9, 'batch': 300, 'loss': 2.4256792068481445}\n",
            "{'epoch': 9, 'batch': 381, 'improved_loss': 0.2981168031692505}\n",
            "{'epoch': 9, 'batch': 400, 'loss': 0.597142219543457}\n",
            "{'epoch': 10, 'batch': 0, 'loss': 1.831783413887024}\n",
            "{'epoch': 10, 'batch': 100, 'loss': 1.1179004907608032}\n",
            "{'epoch': 10, 'batch': 200, 'loss': 0.8812366724014282}\n",
            "{'epoch': 10, 'batch': 300, 'loss': 2.3226535320281982}\n",
            "{'epoch': 10, 'batch': 381, 'improved_loss': 0.2905471622943878}\n",
            "{'epoch': 10, 'batch': 400, 'loss': 0.5840615630149841}\n",
            "{'epoch': 11, 'batch': 0, 'loss': 1.7725709676742554}\n",
            "{'epoch': 11, 'batch': 100, 'loss': 1.0781731605529785}\n",
            "{'epoch': 11, 'batch': 200, 'loss': 0.8581396341323853}\n",
            "{'epoch': 11, 'batch': 300, 'loss': 2.2781825065612793}\n",
            "{'epoch': 11, 'batch': 381, 'improved_loss': 0.2813207805156708}\n",
            "{'epoch': 11, 'batch': 400, 'loss': 0.5748161673545837}\n",
            "{'epoch': 12, 'batch': 0, 'loss': 1.7204269170761108}\n",
            "{'epoch': 12, 'batch': 100, 'loss': 1.049438714981079}\n",
            "{'epoch': 12, 'batch': 200, 'loss': 0.8360442519187927}\n",
            "{'epoch': 12, 'batch': 300, 'loss': 2.1668946743011475}\n",
            "{'epoch': 12, 'batch': 381, 'improved_loss': 0.2730823755264282}\n",
            "{'epoch': 12, 'batch': 400, 'loss': 0.5657427906990051}\n",
            "{'epoch': 13, 'batch': 0, 'loss': 1.6766083240509033}\n",
            "{'epoch': 13, 'batch': 100, 'loss': 1.0348342657089233}\n",
            "{'epoch': 13, 'batch': 200, 'loss': 0.8165639042854309}\n",
            "{'epoch': 13, 'batch': 300, 'loss': 2.0839033126831055}\n",
            "{'epoch': 13, 'batch': 381, 'improved_loss': 0.27071675658226013}\n",
            "{'epoch': 13, 'batch': 400, 'loss': 0.5607221722602844}\n",
            "{'epoch': 14, 'batch': 0, 'loss': 1.6298495531082153}\n",
            "{'epoch': 14, 'batch': 100, 'loss': 1.011755108833313}\n",
            "{'epoch': 14, 'batch': 200, 'loss': 0.7991252541542053}\n",
            "{'epoch': 14, 'batch': 300, 'loss': 1.9950809478759766}\n",
            "{'epoch': 14, 'batch': 381, 'improved_loss': 0.2692432999610901}\n",
            "{'epoch': 14, 'batch': 400, 'loss': 0.546171247959137}\n",
            "{'epoch': 15, 'batch': 0, 'loss': 1.5718193054199219}\n",
            "{'epoch': 15, 'batch': 100, 'loss': 0.9914636015892029}\n",
            "{'epoch': 15, 'batch': 200, 'loss': 0.7801406979560852}\n",
            "{'epoch': 15, 'batch': 300, 'loss': 1.9157041311264038}\n",
            "{'epoch': 15, 'batch': 381, 'improved_loss': 0.26185891032218933}\n",
            "{'epoch': 15, 'batch': 400, 'loss': 0.5408570766448975}\n",
            "{'epoch': 16, 'batch': 0, 'loss': 1.5137470960617065}\n",
            "{'epoch': 16, 'batch': 100, 'loss': 0.9667283892631531}\n",
            "{'epoch': 16, 'batch': 200, 'loss': 0.7662971019744873}\n",
            "{'epoch': 16, 'batch': 300, 'loss': 1.8557820320129395}\n",
            "{'epoch': 16, 'batch': 381, 'improved_loss': 0.25598272681236267}\n",
            "{'epoch': 16, 'batch': 400, 'loss': 0.5327087640762329}\n",
            "{'epoch': 17, 'batch': 0, 'loss': 1.464559555053711}\n",
            "{'epoch': 17, 'batch': 100, 'loss': 0.9403837323188782}\n",
            "{'epoch': 17, 'batch': 200, 'loss': 0.7317931056022644}\n",
            "{'epoch': 17, 'batch': 300, 'loss': 1.7799073457717896}\n",
            "{'epoch': 17, 'batch': 381, 'improved_loss': 0.25507718324661255}\n",
            "{'epoch': 17, 'batch': 400, 'loss': 0.5244337320327759}\n",
            "{'epoch': 18, 'batch': 0, 'loss': 1.3968284130096436}\n",
            "{'epoch': 18, 'batch': 100, 'loss': 0.930798351764679}\n",
            "{'epoch': 18, 'batch': 200, 'loss': 0.7292263507843018}\n",
            "{'epoch': 18, 'batch': 300, 'loss': 1.742936372756958}\n",
            "{'epoch': 18, 'batch': 381, 'improved_loss': 0.24750933051109314}\n",
            "{'epoch': 18, 'batch': 400, 'loss': 0.5246051549911499}\n",
            "{'epoch': 19, 'batch': 0, 'loss': 1.3629435300827026}\n",
            "{'epoch': 19, 'batch': 100, 'loss': 0.9109729528427124}\n",
            "{'epoch': 19, 'batch': 200, 'loss': 0.720447838306427}\n",
            "{'epoch': 19, 'batch': 300, 'loss': 1.6886237859725952}\n",
            "{'epoch': 19, 'batch': 400, 'loss': 0.5195839405059814}\n",
            "{'epoch': 20, 'batch': 0, 'loss': 1.3098273277282715}\n",
            "{'epoch': 20, 'batch': 100, 'loss': 0.8933303356170654}\n",
            "{'epoch': 20, 'batch': 200, 'loss': 0.7041367888450623}\n",
            "{'epoch': 20, 'batch': 300, 'loss': 1.6272104978561401}\n",
            "{'epoch': 20, 'batch': 381, 'improved_loss': 0.24548150599002838}\n",
            "{'epoch': 20, 'batch': 400, 'loss': 0.5111439228057861}\n",
            "{'epoch': 21, 'batch': 0, 'loss': 1.2746552228927612}\n",
            "{'epoch': 21, 'batch': 100, 'loss': 0.87290358543396}\n",
            "{'epoch': 21, 'batch': 200, 'loss': 0.6877186298370361}\n",
            "{'epoch': 21, 'batch': 300, 'loss': 1.5794357061386108}\n",
            "{'epoch': 21, 'batch': 381, 'improved_loss': 0.23939953744411469}\n",
            "{'epoch': 21, 'batch': 400, 'loss': 0.5099043250083923}\n",
            "{'epoch': 22, 'batch': 0, 'loss': 1.2224479913711548}\n",
            "{'epoch': 22, 'batch': 100, 'loss': 0.8608409762382507}\n",
            "{'epoch': 22, 'batch': 200, 'loss': 0.6782251596450806}\n",
            "{'epoch': 22, 'batch': 300, 'loss': 1.5272698402404785}\n",
            "{'epoch': 22, 'batch': 381, 'improved_loss': 0.23693792521953583}\n",
            "{'epoch': 22, 'batch': 400, 'loss': 0.5034761428833008}\n",
            "{'epoch': 23, 'batch': 0, 'loss': 1.1831821203231812}\n",
            "{'epoch': 23, 'batch': 100, 'loss': 0.8521660566329956}\n",
            "{'epoch': 23, 'batch': 200, 'loss': 0.666153609752655}\n",
            "{'epoch': 23, 'batch': 300, 'loss': 1.4642348289489746}\n",
            "{'epoch': 23, 'batch': 400, 'loss': 0.5007714033126831}\n",
            "{'epoch': 24, 'batch': 0, 'loss': 1.1667816638946533}\n",
            "{'epoch': 24, 'batch': 100, 'loss': 0.8300822973251343}\n",
            "{'epoch': 24, 'batch': 200, 'loss': 0.6567069292068481}\n",
            "{'epoch': 24, 'batch': 300, 'loss': 1.4032018184661865}\n",
            "{'epoch': 24, 'batch': 381, 'improved_loss': 0.23379696905612946}\n",
            "{'epoch': 24, 'batch': 400, 'loss': 0.4978049695491791}\n",
            "{'epoch': 25, 'batch': 0, 'loss': 1.118249535560608}\n",
            "{'epoch': 25, 'batch': 100, 'loss': 0.8089886903762817}\n",
            "{'epoch': 25, 'batch': 200, 'loss': 0.6513240933418274}\n",
            "{'epoch': 25, 'batch': 300, 'loss': 1.3723278045654297}\n",
            "{'epoch': 25, 'batch': 400, 'loss': 0.49392515420913696}\n",
            "{'epoch': 26, 'batch': 0, 'loss': 1.0825141668319702}\n",
            "{'epoch': 26, 'batch': 100, 'loss': 0.7988000512123108}\n",
            "{'epoch': 26, 'batch': 200, 'loss': 0.6322616934776306}\n",
            "{'epoch': 26, 'batch': 300, 'loss': 1.332323670387268}\n",
            "{'epoch': 26, 'batch': 381, 'improved_loss': 0.22787342965602875}\n",
            "{'epoch': 26, 'batch': 400, 'loss': 0.49166467785835266}\n",
            "{'epoch': 27, 'batch': 0, 'loss': 1.047442078590393}\n",
            "{'epoch': 27, 'batch': 100, 'loss': 0.7840563654899597}\n",
            "{'epoch': 27, 'batch': 200, 'loss': 0.6342430114746094}\n",
            "{'epoch': 27, 'batch': 300, 'loss': 1.2938907146453857}\n",
            "{'epoch': 27, 'batch': 381, 'improved_loss': 0.2227463275194168}\n",
            "{'epoch': 27, 'batch': 400, 'loss': 0.48433515429496765}\n",
            "{'epoch': 28, 'batch': 0, 'loss': 1.0069931745529175}\n",
            "{'epoch': 28, 'batch': 100, 'loss': 0.7660078406333923}\n",
            "{'epoch': 28, 'batch': 200, 'loss': 0.6252581477165222}\n",
            "{'epoch': 28, 'batch': 300, 'loss': 1.2611079216003418}\n",
            "{'epoch': 28, 'batch': 381, 'improved_loss': 0.22128456830978394}\n",
            "{'epoch': 28, 'batch': 400, 'loss': 0.4768649935722351}\n",
            "{'epoch': 29, 'batch': 0, 'loss': 0.9905698299407959}\n",
            "{'epoch': 29, 'batch': 100, 'loss': 0.7529582977294922}\n",
            "{'epoch': 29, 'batch': 200, 'loss': 0.61662358045578}\n",
            "{'epoch': 29, 'batch': 300, 'loss': 1.222775936126709}\n",
            "{'epoch': 29, 'batch': 381, 'improved_loss': 0.21780845522880554}\n",
            "{'epoch': 29, 'batch': 400, 'loss': 0.4815346598625183}\n",
            "{'epoch': 30, 'batch': 0, 'loss': 0.949659526348114}\n",
            "{'epoch': 30, 'batch': 59, 'improved_loss': 0.21763937175273895}\n",
            "{'epoch': 30, 'batch': 100, 'loss': 0.7507785558700562}\n",
            "{'epoch': 30, 'batch': 200, 'loss': 0.6015763878822327}\n",
            "{'epoch': 30, 'batch': 300, 'loss': 1.1908209323883057}\n",
            "{'epoch': 30, 'batch': 400, 'loss': 0.4835686981678009}\n",
            "{'epoch': 31, 'batch': 0, 'loss': 0.9400709867477417}\n",
            "{'epoch': 31, 'batch': 59, 'improved_loss': 0.212346613407135}\n",
            "{'epoch': 31, 'batch': 100, 'loss': 0.7300398945808411}\n",
            "{'epoch': 31, 'batch': 200, 'loss': 0.6006972789764404}\n",
            "{'epoch': 31, 'batch': 300, 'loss': 1.1690860986709595}\n",
            "{'epoch': 31, 'batch': 400, 'loss': 0.4774952530860901}\n",
            "{'epoch': 32, 'batch': 0, 'loss': 0.9129789471626282}\n",
            "{'epoch': 32, 'batch': 59, 'improved_loss': 0.21223053336143494}\n",
            "{'epoch': 32, 'batch': 100, 'loss': 0.7277249693870544}\n",
            "{'epoch': 32, 'batch': 200, 'loss': 0.5982677936553955}\n",
            "{'epoch': 32, 'batch': 300, 'loss': 1.1312668323516846}\n",
            "{'epoch': 32, 'batch': 400, 'loss': 0.47393447160720825}\n",
            "{'epoch': 33, 'batch': 0, 'loss': 0.9018797278404236}\n",
            "{'epoch': 33, 'batch': 59, 'improved_loss': 0.20768842101097107}\n",
            "{'epoch': 33, 'batch': 100, 'loss': 0.7099905610084534}\n",
            "{'epoch': 33, 'batch': 200, 'loss': 0.5959221124649048}\n",
            "{'epoch': 33, 'batch': 300, 'loss': 1.1159952878952026}\n",
            "{'epoch': 33, 'batch': 400, 'loss': 0.4756602644920349}\n",
            "{'epoch': 34, 'batch': 0, 'loss': 0.8668678402900696}\n",
            "{'epoch': 34, 'batch': 59, 'improved_loss': 0.2053186297416687}\n",
            "{'epoch': 34, 'batch': 100, 'loss': 0.6933232545852661}\n",
            "{'opt_loss': 0.2053186297416687}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load model if needed.\n",
        "\n",
        "# model = LSTMModel() \n",
        "# model.load_state_dict(torch.load(DATA_PATH / 'model_v1.model'))\n",
        "# model.to(DEVICE)"
      ],
      "metadata": {
        "id": "0fq4yfI45Nvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Gc7xP1JR5LS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The predict function is a text generator. You have to modify this code!\n",
        "\n",
        "\n",
        "def predict_single_word( model, state_h, state_c, prompt_words, temp):\n",
        "  x = prompt_words.to(DEVICE)\n",
        "  # y_pred.shape = (seq_len, num_classes)\n",
        "  y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "  # last_word_logits.shape =  (num_classes)\n",
        "  last_word_logits = y_pred[-1]/temp\n",
        "  p = softmax(last_word_logits, dim=0).detach().cpu().numpy()\n",
        "  word_index = np.random.choice(len(last_word_logits), p=p)\n",
        "  # word_index = np.argmax(p)\n",
        "  return word_index, (state_h, state_c)\n",
        "\n",
        "\n",
        "def predict(model, prompt, next_words=15, temp=0.1, textify=True):\n",
        "    model.eval()\n",
        "    batch_size=1\n",
        "    state_h, state_c = model.init_state(batch_size)\n",
        "\n",
        "    ret = prompt.tolist()\n",
        "    if textify:\n",
        "      print(f\"prompt:\\n{vocab.textify(ret)}\")\n",
        "    next_word, (state_h, state_c) = predict_single_word( model, state_h, state_c, prompt, temp=temp)\n",
        "    ret.append(next_word)\n",
        "\n",
        "    for i in range(1, next_words):\n",
        "        x = torch.tensor([next_word])\n",
        "        next_word, (state_h, state_c) = predict_single_word( model, state_h, state_c, x, temp=temp)\n",
        "        ret.append(next_word)\n",
        "\n",
        "    if textify:\n",
        "        ret = vocab.textify(ret)\n",
        "\n",
        "    return ret"
      ],
      "metadata": {
        "id": "VPs3Th7Io1FQ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model, train_dataset[10][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "woDpiVUcnfxh",
        "outputId": "11408b69-6f17-421e-e069-ffa1f5865a33"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt:\n",
            "n77 d16 n65 d17 xxsep d4 n29 d2 xxsep d4 n31 d3 xxsep d4 n33\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'n77 d16 n65 d17 xxsep d4 n29 d2 xxsep d4 n31 d3 xxsep d4 n33 d2 xxsep d2 n63 d2 n59 d2 n54 d2 n51 d2 n46 d2 n39 d2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_fn = DATA_PATH / 'model_v1.model'\n",
        "# torch.save(model.state_dict(), model_fn)\n",
        "\n",
        "# model_wo = LSTMModel() \n",
        "# model_wo.load_state_dict(torch.load(model_fn))\n",
        "# model_wo.to(DEVICE)"
      ],
      "metadata": {
        "id": "hMOep8bKwLkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DQUR76ZMwaR0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}